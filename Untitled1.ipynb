{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM09PtkTTFQ8pRiM9Uzbux+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hazzd12/CASA0018_coursework/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio preprocessing\n",
        "First, we need to convert the original audio file to the Mayer spectrum, a common representation of audio features that is particularly suitable for feeding convolutional neural networks (CNNS) for training."
      ],
      "metadata": {
        "id": "MdY8G9PvjSUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kSJ7DXfcjDf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def audio_to_melspectrogram(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
        "    return mels_db\n"
      ],
      "metadata": {
        "id": "ulq-2cmvirdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5x4Okd0jErb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设我们有以下数据结构\n",
        "audio_paths = ['path/to/audio1.wav', 'path/to/audio2.wav', ...]\n",
        "scores = [3.5, 4.0, ...]  # 假设评分在0到5之间\n",
        "\n",
        "# 将音频文件转换为梅尔频谱特征\n",
        "X_train = np.array([audio_to_melspectrogram(path) for path in audio_paths])\n",
        "y_train = np.array(scores)\n"
      ],
      "metadata": {
        "id": "EpZkCQM_jRKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "        layers.MaxPooling2D(2),\n",
        "        layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='linear')  # 输出层为线性激活函数以预测评分\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# 由于梅尔频谱的大小可能不同，我们需要统一输入尺寸\n",
        "# 这里我们选取或调整到一个固定的大小，比如 (128, 128)\n",
        "X_train_resized = np.array([librosa.util.fix_length(x, size=128*128).reshape(128, 128) for x in X_train])\n",
        "input_shape = X_train_resized.shape[1:] + (1,)\n",
        "\n",
        "# 调整X_train的形状以适配模型的输入\n",
        "X_train_resized = X_train_resized[..., np.newaxis]\n",
        "\n",
        "model = create_model(input_shape)\n"
      ],
      "metadata": {
        "id": "6kltDJynjeh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_resized, y_train, epochs=20, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "eLxi7vASjeok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGj-jjHqjeuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}