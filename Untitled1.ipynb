{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/jX4ouePAZ5EcWaIkpjgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hazzd12/CASA0018_coursework/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio preprocessing\n",
        "First, we need to convert the original audio file to the Mayer spectrum, a common representation of audio features that is particularly suitable for feeding convolutional neural networks (CNNS) for training."
      ],
      "metadata": {
        "id": "MdY8G9PvjSUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kSJ7DXfcjDf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def audio_to_melspectrogram(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mels_db = librosa.power_to_db(mels, ref=np.max)\n",
        "    return mels_db\n"
      ],
      "metadata": {
        "id": "ulq-2cmvirdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n5x4Okd0jErb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设我们有以下数据结构\n",
        "audio_paths = ['path/to/audio1.wav', 'path/to/audio2.wav', ...]\n",
        "scores = [3.5, 4.0, ...]  # 假设评分在0到5之间\n",
        "\n",
        "# 将音频文件转换为梅尔频谱特征\n",
        "X_train = np.array([audio_to_melspectrogram(path) for path in audio_paths])\n",
        "y_train = np.array(scores)\n"
      ],
      "metadata": {
        "id": "EpZkCQM_jRKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n"
      ],
      "metadata": {
        "id": "6kltDJynjeh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_base_network(input_shape):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    return Model(input_layer, x, name=\"base_network\")\n"
      ],
      "metadata": {
        "id": "ct2odwL-qMyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_siamese_network(input_shape):\n",
        "    base_network = create_base_network(input_shape)\n",
        "\n",
        "    input_a = Input(shape=input_shape)\n",
        "    input_b = Input(shape=input_shape)\n",
        "\n",
        "    processed_a = base_network(input_a)\n",
        "    processed_b = base_network(input_b)\n",
        "\n",
        "    distance = Lambda(lambda embeddings: K.abs(embeddings[0] - embeddings[1]))([processed_a, processed_b])\n",
        "    outputs = Dense(1, activation='sigmoid')(distance)\n",
        "    model = Model([input_a, input_b], outputs)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "q-i1mFexqM-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 128, 1)  # 假设我们的梅尔频谱图大小是128x128，单通道\n",
        "siamese_model = create_siamese_network(input_shape)\n",
        "\n",
        "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "eLxi7vASjeok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设数据已经准备好\n",
        "X = [pair_of_spectrograms, ...]  # 每个元素是一个包含一对频谱图的元组\n",
        "y = [label, ...]  # 每个标签表示对应的一对频谱图是否相似\n",
        "\n",
        "# 将数据转换为适合模型训练的格式\n",
        "X_train = [np.array([x[0] for x in X]), np.array([x[1] for x in X])]\n",
        "y_train = np.array(y)\n",
        "\n",
        "# 训练模型\n",
        "siamese_model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "KGj-jjHqjeuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}